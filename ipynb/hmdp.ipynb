{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import io, os, shutil\n",
    "import subprocess\n",
    "import folium\n",
    "    \n",
    "\n",
    "#function to create topic maps based on JSON files by the HMDP topic model\n",
    "def map_from_JSON(base_folder, runs, color='auto', marker_size=10):\n",
    "\n",
    "    #we only create a map for the final run folder.\n",
    "    #comment the next line to create maps for all folders\n",
    "    final_run_folder = base_folder + \"/output_HMDP/\" + str(runs) +\"/\";\n",
    "    \n",
    "    #traverse folders containing geojson files\n",
    "    folders = [x[0] for x in os.walk(final_run_folder) if x[0].endswith(\"_geojson\")];\n",
    "    for folder in folders:\n",
    "        print(\"opening folder \"+folder+\":\");\n",
    "\n",
    "        #Create new folium map class\n",
    "        f_map = folium.Map(location=[50, 6], tiles='Stamen Toner', zoom_start=1);\n",
    "\n",
    "        #traverse geoJSON files\n",
    "        files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) & f.endswith(\".geojson\")];\n",
    "        files.sort();\n",
    "        for file in files:\n",
    "            print(\"processing \"+file+\" ...\");\n",
    "\n",
    "            with open(folder+'/'+file) as f:\n",
    "                geojson = json.load(f)\n",
    "\n",
    "            icon_size = (14, 14)\n",
    "\n",
    "            #traverse geoJSON features\n",
    "            feature_group = folium.FeatureGroup(file.split(\".\")[0]);\n",
    "            for feature in geojson['features']:\n",
    "                #we get position, colour, transparency from JSON\n",
    "                lat, lon = feature['geometry']['coordinates'];\n",
    "                if color == 'auto':\n",
    "                    fillColor = \"#\"+feature['properties']['fillColor'];\n",
    "                else:\n",
    "                    fillColor = color;\n",
    "                fillOpacity = feature['properties']['fillOpacity'];\n",
    "                marker = folium.CircleMarker([lat, lon], \n",
    "                                             fill_color=fillColor, \n",
    "                                             fill_opacity=fillOpacity,\n",
    "                                             color = \"none\",\n",
    "                                             radius = marker_size)\n",
    "                feature_group.add_child(marker);\n",
    "\n",
    "            f_map.add_child(feature_group);\n",
    "            f.close();\n",
    "\n",
    "        #add layer control to activate/deactivate topics\n",
    "        folium.LayerControl().add_to(f_map);    \n",
    "        #save map\n",
    "        f_map.save(folder+'/topic_map.htm')\n",
    "        print('created map in: '+folder+'/topic_map.htm');\n",
    "        \n",
    "#function to call the HMDP topic model. Manual:\n",
    "#https://github.com/gesiscss/promoss\n",
    "def HMDP_topicmodel(\n",
    "    directory,\n",
    "    meta_params,\n",
    "    T=100,\n",
    "    RUNS=200,\n",
    "    SAVE_STEP=10,\n",
    "    TRAINING_SHARE=1.0,\n",
    "    BATCHSIZE=128,\n",
    "    BATCHSIZE_GROUPS=128,\n",
    "    BURNIN=0,\n",
    "    BURNIN_DOCUMENTS=0,\n",
    "    INIT_RAND=0,\n",
    "    SAMPLE_ALPHA=1,\n",
    "    BATCHSIZE_ALPHA=1000,\n",
    "    MIN_DICT_WORDS=100,\n",
    "    alpha_0=1,\n",
    "    alpha_1=1,\n",
    "    epsilon=\"none\",\n",
    "    delta_fix=\"none\",\n",
    "    rhokappa=0.5,\n",
    "    rhotau=64,\n",
    "    rhos=1,\n",
    "    rhokappa_document=0.5,\n",
    "    rhotau_document=64,\n",
    "    rhos_document=1,\n",
    "    rhokappa_group=0.5,\n",
    "    rhotau_group=64,\n",
    "    rhos_group=1,\n",
    "    processed=True,\n",
    "    stemming=False,\n",
    "    stopwords=False,\n",
    "    language=\"en\",\n",
    "    store_empty=True,\n",
    "    topk=100):\n",
    " \n",
    "    print(\"Running HMDP topic model... (please wait)\");\n",
    "    \n",
    "    #if os.path.is_dir(directory+\"/output_HMDP\"):\n",
    "    #    shutil.rmtree(directory+\"/output_HMDP\") \n",
    "    if os.path.isdir(directory+\"/cluster_desc\"):\n",
    "        shutil.rmtree(directory+\"/cluster_desc\") \n",
    "    \n",
    "    if os.path.isfile(directory+\"/groups\"):\n",
    "        os.remove(directory+\"/groups\")\n",
    "    if os.path.isfile(directory+\"/groups.txt\"):\n",
    "        os.remove(directory+\"/groups.txt\")\n",
    "    #os.remove(directory+\"/texts.txt\")\n",
    "    #os.remove(directory+\"/words.txt\")\n",
    "    #os.remove(directory+\"/wordsets\")\n",
    "    \n",
    "    if not os.path.isfile(\"../promoss.jar\"):\n",
    "        print(\"Could not find ../promoss.jar. Exit\")\n",
    "        return;\n",
    "\n",
    "    \n",
    "    process = subprocess.Popen(['java', '-jar', '../promoss.jar', \n",
    "                        '-directory', directory, \n",
    "                        '-T',str(T),\n",
    "                        '-RUNS',str(RUNS),\n",
    "                        '-SAVE_STEP',str(SAVE_STEP),\n",
    "                        '-TRAINING_SHARE',str(TRAINING_SHARE),\n",
    "                        '-BATCHSIZE',str(BATCHSIZE),\n",
    "                        '-BATCHSIZE_GROUPS',str(BATCHSIZE_GROUPS),\n",
    "                        '-BURNIN',str(BURNIN),\n",
    "                        '-BURNIN_DOCUMENTS',str(BURNIN_DOCUMENTS),\n",
    "                        '-INIT_RAND',str(INIT_RAND),\n",
    "                        '-SAMPLE_ALPHA',str(SAMPLE_ALPHA),\n",
    "                        '-BATCHSIZE_ALPHA',str(BATCHSIZE_ALPHA),\n",
    "                        '-MIN_DICT_WORDS',str(MIN_DICT_WORDS),\n",
    "                        '-alpha_0',str(alpha_0),\n",
    "                        '-alpha_1',str(alpha_1),\n",
    "                        '-epsilon',str(epsilon),\n",
    "                        '-delta_fix',str(delta_fix),\n",
    "                        '-rhokappa',str(rhokappa),\n",
    "                        '-rhotau',str(rhotau),\n",
    "                        '-rhos',str(rhos),\n",
    "                        '-rhokappa_document',str(rhokappa_document),\n",
    "                        '-rhotau_document',str(rhotau_document),\n",
    "                        '-rhos_document',str(rhos_document),\n",
    "                        '-rhokappa_group',str(rhokappa_group),\n",
    "                        '-rhotau_group',str(rhotau_group),\n",
    "                        '-rhos_group',str(rhos_group),\n",
    "                        '-processed',str(processed),\n",
    "                        '-stemming',str(stemming),\n",
    "                        '-stopwords',str(stopwords),\n",
    "                        '-language',str(language),\n",
    "                        '-store_empty',str(store_empty),\n",
    "                        '-topk',str(topk)\n",
    "                        ], stdout=subprocess.PIPE)    \n",
    "    output = \"\";\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if (output == '') | (process.poll() is not None):\n",
    "            break\n",
    "        if output:\n",
    "            output = str(output).strip()[2:-1].replace(\"\\\\n\",\"\");\n",
    "            print(output)\n",
    "    rc = process.poll()\n",
    "    \n",
    "    print(\"...creating maps...\");\n",
    "    map_from_JSON(directory,RUNS);\n",
    "    print(\"...done.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMDP topic model... (please wait)\n",
      "Clustering metadata...\n",
      "Geographical clustering step 0 (Likelihood: 1.0)\n",
      "Geographical clustering step 1 (Likelihood: -3476497.185869844)\n",
      "Geographical clustering step 2 (Likelihood: -2.10056534254786355E18)\n",
      "Geographical clustering step 3 (Likelihood: -2.03048703021529728E18)\n",
      "Creating dictionary...\n",
      "Initialising parameters...\n",
      "Reading groups...\n",
      "Processing documents...\n",
      ".....................................................\n",
      "Estimating topics...\n",
      "/home/c/work/topicmodels/geo_test/ run 0 (Topics 0 alpha_0 1.0 alpha_1 1.0 beta_0 0.01 gamma 1.0 delta 1.0 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 1 (Topics 10 alpha_0 1.0 alpha_1 1.0 beta_0 0.01 gamma 1.0 delta 1.0 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 2 (Topics 10 alpha_0 5.120616947348738 alpha_1 1.0 beta_0 0.06995314512172907 gamma 1.0 delta 74.7200570359124 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 3 (Topics 10 alpha_0 10.4047219155533 alpha_1 1.0 beta_0 0.13068635601657197 gamma 1.3030152172618794 delta 145.8219404951486 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 4 (Topics 10 alpha_0 15.39773985380889 alpha_1 1.0 beta_0 0.16717774207504424 gamma 1.2604064999076314 delta 214.66107196216302 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 5 (Topics 10 alpha_0 20.13130854094592 alpha_1 1.0 beta_0 0.18489021279167864 gamma 1.2320700145572205 delta 281.55771607145573 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 6 (Topics 10 alpha_0 24.655847027524114 alpha_1 1.0 beta_0 0.19156579672653998 gamma 1.2112811874858793 delta 346.80692921871173 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 7 (Topics 9 alpha_0 28.99666609569224 alpha_1 1.0 beta_0 0.1925570344720232 gamma 1.195435439827623 delta 410.687145136333 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 8 (Topics 9 alpha_0 33.163628082950204 alpha_1 1.0 beta_0 0.1897495427157918 gamma 1.1841917547572143 delta 473.46983803839385 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 9 (Topics 9 alpha_0 37.159786448289346 alpha_1 1.0 beta_0 0.18513426016557097 gamma 1.1752478647323101 delta 535.4159706344639 epsilon 1.0\n",
      ".....................................................\n",
      "Storing variables...\n",
      "/home/c/work/topicmodels/geo_test/ run 10 (Topics 9 alpha_0 40.985456990660694 alpha_1 1.0 beta_0 0.17925971735054239 gamma 1.167908086881029 delta 596.7532165452362 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 11 (Topics 9 alpha_0 44.63672732270658 alpha_1 1.0 beta_0 0.17299887049063706 gamma 1.163049401321918 delta 657.6686353763971 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 12 (Topics 9 alpha_0 48.111003929387465 alpha_1 1.0 beta_0 0.16658901702871 gamma 1.1590691935981459 delta 718.3032201911162 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 13 (Topics 9 alpha_0 51.405611634193 alpha_1 1.0 beta_0 0.16005915096531884 gamma 1.156053764662566 delta 778.7592369386533 epsilon 1.0\n",
      ".....................................................\n",
      "/home/c/work/topicmodels/geo_test/ run 14 (Topics 9 alpha_0 54.51854791606581 alpha_1 1.0 beta_0 0.15347217897451546 gamma 1.1542688539504133 delta 839.1123290160941 epsilon 1.0\n"
     ]
    }
   ],
   "source": [
    "#directory of meta.txt and corpus.txt\n",
    "directory = \"/home/c/work/topicmodels/geo_test/\";\n",
    "#the first value in meta.txt are Geographical coordinates\n",
    "#and we want to detect 100 clusters\n",
    "meta_params = \"G(100)\";\n",
    "#10 topics\n",
    "T = 10;\n",
    "#we only keep words which appear at least 2 times\n",
    "MIN_DICT_WORDS = 2;\n",
    "#run model\n",
    "HMDP_topicmodel(directory,meta_params,T,MIN_DICT_WORDS=MIN_DICT_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
