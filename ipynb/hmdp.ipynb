{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import json\n",
    "import io, os, shutil, time, datetime\n",
    "import subprocess\n",
    "import folium\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import IFrame, display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "class HMDP(object):\n",
    "    directory = \"\";\n",
    "    meta_params = \"\";\n",
    "    T=100\n",
    "    RUNS=200\n",
    "    SAVE_STEP=10\n",
    "    TRAINING_SHARE=1.0\n",
    "    BATCHSIZE=128\n",
    "    BATCHSIZE_GROUPS=128\n",
    "    BURNIN=0\n",
    "    BURNIN_DOCUMENTS=0\n",
    "    INIT_RAND=0\n",
    "    SAMPLE_ALPHA=1\n",
    "    BATCHSIZE_ALPHA=1000\n",
    "    MIN_DICT_WORDS=100\n",
    "    alpha_0=1\n",
    "    alpha_1=1\n",
    "    epsilon=\"none\"\n",
    "    delta_fix=\"none\"\n",
    "    rhokappa=0.5\n",
    "    rhotau=64\n",
    "    rhos=1\n",
    "    rhokappa_document=0.5\n",
    "    rhotau_document=64\n",
    "    rhos_document=1\n",
    "    rhokappa_group=0.5\n",
    "    rhotau_group=64\n",
    "    rhos_group=1\n",
    "    processed=True\n",
    "    stemming=False\n",
    "    stopwords=False\n",
    "    language=\"en\"\n",
    "    store_empty=True\n",
    "    topk=100\n",
    "    \n",
    "    def __init__(self,\n",
    "    directory,\n",
    "    meta_params,\n",
    "    T=100,\n",
    "    RUNS=200,\n",
    "    SAVE_STEP=10,\n",
    "    TRAINING_SHARE=1.0,\n",
    "    BATCHSIZE=128,\n",
    "    BATCHSIZE_GROUPS=128,\n",
    "    BURNIN=0,\n",
    "    BURNIN_DOCUMENTS=0,\n",
    "    INIT_RAND=0,\n",
    "    SAMPLE_ALPHA=1,\n",
    "    BATCHSIZE_ALPHA=1000,\n",
    "    MIN_DICT_WORDS=100,\n",
    "    alpha_0=1,\n",
    "    alpha_1=1,\n",
    "    epsilon=\"none\",\n",
    "    delta_fix=\"none\",\n",
    "    rhokappa=0.5,\n",
    "    rhotau=64,\n",
    "    rhos=1,\n",
    "    rhokappa_document=0.5,\n",
    "    rhotau_document=64,\n",
    "    rhos_document=1,\n",
    "    rhokappa_group=0.5,\n",
    "    rhotau_group=64,\n",
    "    rhos_group=1,\n",
    "    processed=True,\n",
    "    stemming=False,\n",
    "    stopwords=False,\n",
    "    language=\"en\",\n",
    "    store_empty=True,\n",
    "    topk=100):\n",
    "        self.directory = directory\n",
    "        self.meta_params = meta_params\n",
    "        self.T = T\n",
    "        self.RUNS = RUNS\n",
    "        self.SAVE_STEP = SAVE_STEP\n",
    "        self.TRAINING_SHARE = TRAINING_SHARE\n",
    "        self.BATCHSIZE = BATCHSIZE\n",
    "        self.BATCHSIZE_GROUPS = BATCHSIZE_GROUPS\n",
    "        self.BURNIN = BURNIN\n",
    "        self.BURNIN_DOCUMENTS = BURNIN_DOCUMENTS\n",
    "        self.INIT_RAND = INIT_RAND\n",
    "        self.SAMPLE_ALPHA = SAMPLE_ALPHA\n",
    "        self.BATCHSIZE_ALPHA = BATCHSIZE_ALPHA\n",
    "        self.MIN_DICT_WORDS = MIN_DICT_WORDS\n",
    "        self.alpha_0 = alpha_0\n",
    "        self.alpha_1 = alpha_1\n",
    "        self.epsilon = epsilon\n",
    "        self.delta_fix = delta_fix\n",
    "        self.rhokappa = rhokappa\n",
    "        self.rhotau = rhotau\n",
    "        self.rhos = rhos\n",
    "        self.rhokappa_document = rhokappa_document\n",
    "        self.rhotau_document = rhotau_document\n",
    "        self.rhos_document = rhos_document\n",
    "        self.rhokappa_group = rhokappa_group\n",
    "        self.rhotau_group = rhotau_group\n",
    "        self.rhos_group = rhos_group\n",
    "        self.processed = processed\n",
    "        self.stemming = stemming\n",
    "        self.stopwords = stopwords\n",
    "        self.language = language\n",
    "        self.store_empty = store_empty\n",
    "        self.topk = topk\n",
    "\n",
    "    def run(self, RUNS = None):\n",
    "        if RUNS == None:\n",
    "            RUNS = self.RUNS;\n",
    "            \n",
    "        print(\"Running HMDP topic model... (please wait)\");\n",
    "\n",
    "        if os.path.isdir(directory+\"/output_HMDP\"):\n",
    "            shutil.rmtree(directory+\"/output_HMDP\") \n",
    "        if os.path.isdir(self.directory+\"/cluster_desc\"):\n",
    "            shutil.rmtree(self.directory+\"/cluster_desc\") \n",
    "\n",
    "        if os.path.isfile(self.directory+\"/groups\"):\n",
    "            os.remove(self.directory+\"/groups\")\n",
    "        if os.path.isfile(self.directory+\"/groups.txt\"):\n",
    "            os.remove(self.directory+\"/groups.txt\")\n",
    "        if os.path.isfile(self.directory+\"/text.txt\"):\n",
    "            os.remove(self.directory+\"/text.txt\")\n",
    "        if os.path.isfile(self.directory+\"/words.txt\"):\n",
    "            os.remove(self.directory+\"/words.txt\")\n",
    "        if os.path.isfile(self.directory+\"/wordsets\"):\n",
    "            os.remove(self.directory+\"/wordsets\")\n",
    "\n",
    "        if not os.path.isfile(\"../promoss.jar\"):\n",
    "            print(\"Could not find ../promoss.jar. Exit\")\n",
    "            return;\n",
    "        try:\n",
    "            with subprocess.Popen(['java', '-jar', '../promoss.jar', \n",
    "                                '-directory', self.directory, \n",
    "                                '-meta_params', self.meta_params, \n",
    "                                '-T',str(self.T),\n",
    "                                '-RUNS',str(self.RUNS),\n",
    "                                '-SAVE_STEP',str(self.SAVE_STEP),\n",
    "                                '-TRAINING_SHARE',str(self.TRAINING_SHARE),\n",
    "                                '-BATCHSIZE',str(self.BATCHSIZE),\n",
    "                                '-BATCHSIZE_GROUPS',str(self.BATCHSIZE_GROUPS),\n",
    "                                '-BURNIN',str(self.BURNIN),\n",
    "                                '-BURNIN_DOCUMENTS',str(self.BURNIN_DOCUMENTS),\n",
    "                                '-INIT_RAND',str(self.INIT_RAND),\n",
    "                                '-SAMPLE_ALPHA',str(self.SAMPLE_ALPHA),\n",
    "                                '-BATCHSIZE_ALPHA',str(self.BATCHSIZE_ALPHA),\n",
    "                                '-MIN_DICT_WORDS',str(self.MIN_DICT_WORDS),\n",
    "                                '-alpha_0',str(self.alpha_0),\n",
    "                                '-alpha_1',str(self.alpha_1),\n",
    "                                '-epsilon',str(self.epsilon),\n",
    "                                '-delta_fix',str(self.delta_fix),\n",
    "                                '-rhokappa',str(self.rhokappa),\n",
    "                                '-rhotau',str(self.rhotau),\n",
    "                                '-rhos',str(self.rhos),\n",
    "                                '-rhokappa_document',str(self.rhokappa_document),\n",
    "                                '-rhotau_document',str(self.rhotau_document),\n",
    "                                '-rhos_document',str(self.rhos_document),\n",
    "                                '-rhokappa_group',str(self.rhokappa_group),\n",
    "                                '-rhotau_group',str(self.rhotau_group),\n",
    "                                '-rhos_group',str(self.rhos_group),\n",
    "                                '-processed',str(self.processed),\n",
    "                                '-stemming',str(self.stemming),\n",
    "                                '-stopwords',str(self.stopwords),\n",
    "                                '-language',str(self.language),\n",
    "                                '-store_empty',str(self.store_empty),\n",
    "                                '-topk',str(self.topk)\n",
    "                                ], stdout=subprocess.PIPE, stderr=subprocess.PIPE) as p:   \n",
    "\n",
    "                for line in p.stdout:\n",
    "                    line = str(line)[2:-1].replace(\"\\\\n\",\"\").replace(\"\\\\t\",\"   \")\n",
    "                    print(line, end='\\n');\n",
    "                for line in p.stderr:\n",
    "                    line = str(line)[2:-1].replace(\"\\\\n\",\"\").replace(\"\\\\t\",\"   \")\n",
    "                    print(line, end='\\n');\n",
    "\n",
    "                \n",
    "            #rc = process.poll();\n",
    "            #print(\"Finished with return code \" + str(rc));\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(e.returncode)\n",
    "            print(e.output)\n",
    "\n",
    "    def check_run(self):\n",
    "        if os.path.isdir(self.directory + \"/output_HMDP/\" + str(self.RUNS)):\n",
    "            return True;\n",
    "        else:\n",
    "            print(\"Please call run() first\");\n",
    "            return False;\n",
    "            \n",
    "            \n",
    "    #returns the command which we used to call the java file\n",
    "    def get_command(self):\n",
    "        args = ['java', '-jar', '../promoss.jar', \n",
    "                                '-directory', self.directory, \n",
    "                                '-meta_params', self.meta_params, \n",
    "                                '-T',str(self.T),\n",
    "                                '-RUNS',str(self.RUNS),\n",
    "                                '-SAVE_STEP',str(self.SAVE_STEP),\n",
    "                                '-TRAINING_SHARE',str(self.TRAINING_SHARE),\n",
    "                                '-BATCHSIZE',str(self.BATCHSIZE),\n",
    "                                '-BATCHSIZE_GROUPS',str(self.BATCHSIZE_GROUPS),\n",
    "                                '-BURNIN',str(self.BURNIN),\n",
    "                                '-BURNIN_DOCUMENTS',str(self.BURNIN_DOCUMENTS),\n",
    "                                '-INIT_RAND',str(self.INIT_RAND),\n",
    "                                '-SAMPLE_ALPHA',str(self.SAMPLE_ALPHA),\n",
    "                                '-BATCHSIZE_ALPHA',str(self.BATCHSIZE_ALPHA),\n",
    "                                '-MIN_DICT_WORDS',str(self.MIN_DICT_WORDS),\n",
    "                                '-alpha_0',str(self.alpha_0),\n",
    "                                '-alpha_1',str(self.alpha_1),\n",
    "                                '-epsilon',str(self.epsilon),\n",
    "                                '-delta_fix',str(self.delta_fix),\n",
    "                                '-rhokappa',str(self.rhokappa),\n",
    "                                '-rhotau',str(self.rhotau),\n",
    "                                '-rhos',str(self.rhos),\n",
    "                                '-rhokappa_document',str(self.rhokappa_document),\n",
    "                                '-rhotau_document',str(self.rhotau_document),\n",
    "                                '-rhos_document',str(self.rhos_document),\n",
    "                                '-rhokappa_group',str(self.rhokappa_group),\n",
    "                                '-rhotau_group',str(self.rhotau_group),\n",
    "                                '-rhos_group',str(self.rhos_group),\n",
    "                                '-processed',str(self.processed),\n",
    "                                '-stemming',str(self.stemming),\n",
    "                                '-stopwords',str(self.stopwords),\n",
    "                                '-language',str(self.language),\n",
    "                                '-store_empty',str(self.store_empty),\n",
    "                                '-topk',str(self.topk)\n",
    "                                ];\n",
    "        return (\" \".join(args));\n",
    "        \n",
    "    #function to create topic maps based on JSON files by the HMDP topic model\n",
    "    def map_from_JSON(self, base_folder = None, runs = None, color='auto', marker_size=10, show_map=False):\n",
    "\n",
    "        if not self.check_run():\n",
    "            return;\n",
    "        \n",
    "        if base_folder == None:\n",
    "            base_folder = self.directory;\n",
    "        if runs == None:\n",
    "            runs = self.RUNS;\n",
    "            \n",
    "        topics = self.get_topics();\n",
    "        k = min(3,len(topics.iloc[0]));\n",
    "        \n",
    "        #we only create a map for the final run folder.\n",
    "        #comment the next line to create maps for all folders\n",
    "        final_run_folder = base_folder + \"/output_HMDP/\" + str(runs) +\"/\";\n",
    "\n",
    "        #traverse folders containing geojson files\n",
    "        folders = [x[0] for x in os.walk(final_run_folder) if x[0].endswith(\"_geojson\")];\n",
    "        \n",
    "        if (len(folders)==0):\n",
    "            print(\"No geoJSON data found. Does your model contain geographical metadata?\");\n",
    "            return;\n",
    "        \n",
    "        for folder in folders:\n",
    "            print(\"opening folder \"+folder+\":\");\n",
    "\n",
    "            #Create new folium map class\n",
    "            f_map = folium.Map(location=[50, 6], tiles='Stamen Toner', zoom_start=1);\n",
    "\n",
    "            #traverse geoJSON files\n",
    "            files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) & f.endswith(\".geojson\")];\n",
    "            \n",
    "            topic_numbers = [\"\"]*len(files);\n",
    "            \n",
    "            for i in range(0,len(files)):\n",
    "                topic_numbers[i] = int(files[i].split(\"_\")[1].split(\".\")[0]);\n",
    "           \n",
    "            files = [x for (y,x) in sorted(zip(topic_numbers,files))]\n",
    "            \n",
    "            i = 0;\n",
    "            for file in files:\n",
    "                print(\"processing \"+file+\" ...\");\n",
    "\n",
    "                with open(folder+'/'+file) as f:\n",
    "                    geojson = json.load(f)\n",
    "\n",
    "                icon_size = (14, 14)\n",
    "\n",
    "                #name of the topic are the first three topic words\n",
    "                name = \"Topic \"+str(i)+\": \"+\" \".join(topics.iloc[0:k][i]);        \n",
    "                #traverse geoJSON features\n",
    "                feature_group = folium.FeatureGroup(name);\n",
    "                for feature in geojson['features']:\n",
    "                    #we get position, colour, transparency from JSON\n",
    "                    lat, lon = feature['geometry']['coordinates'];\n",
    "                    if color == 'auto':\n",
    "                        fillColor = \"#\"+feature['properties']['fillColor'];\n",
    "                    else:\n",
    "                        fillColor = color;\n",
    "                    fillOpacity = feature['properties']['fillOpacity'];\n",
    "                    marker = folium.CircleMarker([lat, lon], \n",
    "                                                 fill_color=fillColor, \n",
    "                                                 fill_opacity=fillOpacity,\n",
    "                                                 color = \"none\",\n",
    "                                                 radius = marker_size)\n",
    "                    feature_group.add_child(marker);\n",
    "\n",
    "                f_map.add_child(feature_group);\n",
    "                f.close();\n",
    "                i=i+1;\n",
    "\n",
    "            #add layer control to activate/deactivate topics\n",
    "            folium.LayerControl().add_to(f_map);    \n",
    "            #save map\n",
    "            f_map.save(folder+'/topic_map.htm')\n",
    "            print('created map in: '+folder+'/topic_map.htm');\n",
    "            f_map._repr_html_();\n",
    "            #show map only if wanted, can consume quite some memory\n",
    "            if show_map:\n",
    "                if not os.path.exists(\"tmp\"):\n",
    "                    os.makedirs(\"tmp\");\n",
    "\n",
    "                f_map.save(\"tmp/\"+folder.split(\"/\")[-1]+\"_map.html\");\n",
    "                display(IFrame(\"tmp/\"+folder.split(\"/\")[-1]+\"_map.html\",width=400, height=400));\n",
    "                display(f_map._repr_png());\n",
    "            display(HTML('<a href=\"file://'+folder+'/topic_map.htm'+'\" target=\"_blank\">Link to map of '+folder.split(\"/\")[-1].replace(\"_geojson\",\"\")+'</a>'));\n",
    "\n",
    "    #plot topic proportions\n",
    "    def plot_zeta(self, directory=None, RUNS=None):\n",
    "        \n",
    "        if not self.check_run():\n",
    "            return;\n",
    "        \n",
    "        if directory == None:\n",
    "            directory = self.directory;\n",
    "        if RUNS == None:\n",
    "            RUNS = self.RUNS;\n",
    "            \n",
    "        fig = plt.figure();\n",
    "        \n",
    "        zeta_file = self.directory + \"/output_HMDP/\" + str(RUNS) +\"/zeta\";\n",
    "        \n",
    "        df = pd.read_csv(zeta_file, header=None);\n",
    "               \n",
    "        plt.bar(range(0,len(df[0])),df[0]);\n",
    "        plt.xlabel(\"Features\");\n",
    "        plt.ylabel(\"Feature weight\");\n",
    "        plt.show();\n",
    "        \n",
    "        return(fig);\n",
    "    \n",
    "    #read topics ad DataFrame\n",
    "    def get_topics(self, directory=None, RUNS=None):\n",
    "        \n",
    "        if not self.check_run():\n",
    "            return;\n",
    "        \n",
    "        if directory == None:\n",
    "            directory = self.directory;\n",
    "        if RUNS == None:\n",
    "            RUNS = self.RUNS;\n",
    "            \n",
    "        \n",
    "        topic_file = self.directory + \"/output_HMDP/\" + str(RUNS) +\"/topktopic_words\";\n",
    "        \n",
    "        df = pd.read_csv(topic_file, header=None, sep=\" \");\n",
    "                \n",
    "        return(df);\n",
    "    \n",
    "    #plot topic probabilities over time\n",
    "    def plot_time(self, topic_ID, directory=None, RUNS=None):\n",
    "        \n",
    "        if not self.check_run():\n",
    "            return;\n",
    "        \n",
    "        if directory == None:\n",
    "            directory = self.directory;\n",
    "        if RUNS == None:\n",
    "            RUNS = self.RUNS;           \n",
    "            \n",
    "        topics = self.get_topics();\n",
    "        k = min(3,len(topics.iloc[0]));\n",
    "        \n",
    "        #traverse folders containing time files\n",
    "        time_files = [x for x in os.listdir(directory+\"/cluster_desc/\") if x.endswith(\"_L\")];\n",
    "\n",
    "       \n",
    "        figs = [];\n",
    "        \n",
    "        for time_file in time_files:\n",
    "            \n",
    "            time_file = directory+\"/cluster_desc/\"+time_file;\n",
    "            \n",
    "            cluster_number = int(time_file.split(\"/\")[-1][7:-2]);\n",
    "        \n",
    "            times = pd.read_csv(time_file, header=None, sep=\" \");\n",
    "            times = times[1];\n",
    "            \n",
    "            #print(times);\n",
    "            \n",
    "            first_time = min(times);\n",
    "            last_time = max(times);            \n",
    "            \n",
    "            first_date = datetime.datetime.fromtimestamp(\n",
    "                    int(first_time)\n",
    "                    ).strftime('%d.%m.%Y');            \n",
    "            last_date = datetime.datetime.fromtimestamp(\n",
    "                    int(last_time)\n",
    "                    ).strftime('%d.%m.%Y');\n",
    "\n",
    "            fig = plt.figure();\n",
    "\n",
    "            cluster_file = self.directory + \"/output_HMDP/\" + str(RUNS) +\"/clusters_\"+str(cluster_number);\n",
    "           \n",
    "            probabilities = pd.read_csv(cluster_file, header=None);\n",
    "            topic_probabilities = probabilities[topic_ID];\n",
    "\n",
    "            topic_probabilities = [x for (y,x) in sorted(zip(times,topic_probabilities))]\n",
    "            times = sorted(times);\n",
    "\n",
    "            \n",
    "            #name of the topic are the first three topic words\n",
    "            name = \"Topic \"+str(topic_ID)+\": \"+\" \".join(topics.iloc[0:k][topic_ID]);\n",
    "            \n",
    "            fig = plt.figure();\n",
    "            \n",
    "            #print(times)\n",
    "            #print(topic_probabilities)\n",
    "            \n",
    "            plt.scatter(times, topic_probabilities);\n",
    "            plt.xticks([first_time,last_time],[first_date,last_date]);\n",
    "            plt.xlabel(\"Time\");\n",
    "            plt.ylabel(\"Topic probability\");\n",
    "            plt.legend([name]);\n",
    "            plt.show();\n",
    "            figs.append(fig);\n",
    "        \n",
    "        return(figs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
